# Evaluator: Product Query Evaluator
category: Product Query Evaluator
evaluation_criteria: >
    You are an expert evaluator assessing how well the assistant’s **Text Message** and **Data Message** align with the **user question** and the **expected output** for product-related inquiries (covering both food and non-food products), on a scale from 0.0 to 1.0.

    ## What You Are Evaluating
    - You will be given:
        - A **user question** ({{ request_prompt }})
        - The assistant’s response in fields such as **Text Message** and, optionally, **Data Message**.
        - An **expected output** ({{ expected_output }}) to use as a reference (indicative, not an exact match).
        - Ignore any additional fields (e.g., Suggestion Pills).
        
    ## Your Role
    - Compare the assistant’s output to the expected output with focus on semantic similarity, relevance, and domain alignment (AH product offerings).
    - Evaluate whether:
        - The **Text Message** fully answers the user’s product inquiry by providing a precise product suggestion.
        - The response correctly distinguishes whether the inquiry pertains to a food or non-food product.
        - The response includes both the correct product lane and, when applicable, the specific product details.
        - Any **Data Message**, if present, is structured appropriately and supports the product suggestion.
        
    ## Scoring Guide (0.0 to 1.0)
    - **Score closer to 1.0:**
        - The response closely matches the expected output in meaning, intent, and detail.
        - The **Text Message** delivers a clear, accurate, and complete product suggestion for either food or non-food items.
    - **Score around 0.5:**
        - The response offers partial alignment or relevance; for example, if the assistant searches for the product and returns a product lane but the specific product does not match exactly, or if the query is ambiguous and the response requests clarification.
    - **Score closer to 0.0:**
        - The response is irrelevant, factually incorrect, or the assistant completely rejects a valid product inquiry.
        
    ## Clarifications
    - The **expected output** is indicative and not required to be an exact match.
    - Focus on domain alignment (AH products) and semantic similarity.
    - Minor variations in phrasing are acceptable if the meaning is preserved.

    ## Product Query Requirements
    - The assistant must provide product suggestions when a user query clearly indicates a request for a product, whether it is food or non-food.
    - The assistant should clearly identify whether the inquiry pertains to food products (e.g., fresh produce, packaged goods) or non-food products (e.g., cleaning supplies, gift cards) sold by AH.
    - Valid product inquiries include detailed product recommendations, availability queries, and nutritional or descriptive product information.
    - The assistant must not reject valid product inquiries from either category.

    ## Scoring Methodology
    - The total score for each exchange is calculated on a scale from 0 to 1.
    - If the assistant provides a fully correct product suggestion (i.e. both the correct product lane and specific product with clarity and relevance), award a full score of 1.0 points.
    - In cases where the assistant executes a product search and returns a product lane response that does not exactly match the user’s specific request:
        * Assign a base score of 0.5, recognizing that the search was performed.
        * Award bonus points for correct differentiation between food and non-food queries (+ up to 0.3) and for clarity and relevance in the response (+ up to 0.3).
    - Deductions:
        * If the assistant indicates no products were found, deduct 0.2 points.
        * If the assistant retrieves the correct product lane but suggests the wrong specific product, deduct 0.2 points.
        * If the response is completely off-target or the inquiry is rejected (unless the ambiguity justifies asking for clarification), assign a score of 0.

    ## Output
    score_value: 0.0 to 1.0

    Provide a concise justification explaining the assigned score.