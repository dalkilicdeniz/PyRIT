{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "701e43c8-fbe3-4e9c-addb-1e9f0ae27328",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# üöÄ Automated Evaluation of AH-GPT Responses using PyRIT\n",
    "\n",
    "## **üìå Overview**\n",
    "This notebook evaluates the responses of **AH-GPT** using the **PyRIT** framework. It sends predefined prompts to AH-GPT, evaluates the responses, and generates a report.\n",
    "\n",
    "## **üõ†Ô∏è Steps in this Notebook**\n",
    "- ** Configuration** - Set up API endpoints and authentication.\n",
    "- **üìã Load QA Dataset** - Define test questions and expected answers.\n",
    "- **üöÄ Initialize PyRIT** - Configure the testing environment.\n",
    "- **üîÑ Create Chat Threads** - Set up conversation threads.\n",
    "- **üì° Send Prompts & Evaluate Responses** - Run the main test loop.\n",
    "- **üìä Generate Report** - Save the results for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24e286d-08b0-4217-a02d-95a2c6a8308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import asyncio\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# PyRIT Imports\n",
    "from pyrit.common import IN_MEMORY, initialize_pyrit\n",
    "from pyrit.prompt_target import OpenAIChatTarget, AHGPTHttpTarget\n",
    "from pyrit.score.evaluator import Evaluator\n",
    "from pyrit.orchestrator import AHGPTPromptSendingOrchestrator\n",
    "from pyrit.common.text_helper import save_html_report, generate_single_turn_html_report\n",
    "from pyrit.prompt_target import AHGPTResponseParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fcc38e-2ea9-435d-b6d0-f99f120f1e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "BASE_URL = os.getenv(\"AH_GPT_NONPRD_ENDPOINT\")\n",
    "TOKEN = os.getenv(\"AH_GPT_NONPRD_TOKEN\")\n",
    "\n",
    "# Headers for API Requests\n",
    "HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-Authorization\": TOKEN,\n",
    "    \"Accept\": \"*/*\"\n",
    "}\n",
    "\n",
    "# Payload for creating a chat thread\n",
    "thread_init_payload = {\n",
    "    \"message\": \"Hello, start this chat!\",\n",
    "    \"model\": \"gpt-4o-mini\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "896f8251-c0d2-4cb1-a43b-679efaaae8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = [\n",
    "    {\"question\": \"Where can I find my working hours\", \"expected_outcomes\": \"text_message: Under SAM timesheet\"},\n",
    "    {\"question\": \"Give me a nice recipe\", \"expected_outcomes\": \"text_message: [a nice recipe definition]\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc32a30-2849-48a9-afa0-9535ff2e1dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_pyrit(memory_db_type=IN_MEMORY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c99ac6b4-73c2-4344-a499-fd9cab4be0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "http_prompt_target = AHGPTHttpTarget(\n",
    "    http_request=f\"\"\"\n",
    "        POST {BASE_URL}/{{CHAT_ID}}/messages/stream\n",
    "        Content-Type: application/json\n",
    "        X-Authorization: {TOKEN}\n",
    "        Accept: */*\n",
    "\n",
    "        {{\n",
    "            \"message\": \"{{PROMPT}}\"\n",
    "        }}\n",
    "    \"\"\",\n",
    "    prompt_regex_string=\"{PROMPT}\",\n",
    "    timeout=60.0,\n",
    "    callback_function=AHGPTResponseParser.parse_response\n",
    ")\n",
    "\n",
    "scorer = Evaluator(\n",
    "    chat_target=OpenAIChatTarget(),\n",
    "    evaluator_yaml_path=Path(\"assets/AH_Evaluators/ah_gpt/ah_gpt_dataset_evaluator.yaml\"),\n",
    "    scorer_type=\"float_scale\"\n",
    ")\n",
    "\n",
    "orchestrator = AHGPTPromptSendingOrchestrator(\n",
    "    objective_target=http_prompt_target,\n",
    "    scorers=[scorer]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e686ec86-c948-4d00-aaf6-941112cb7a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chat_threads(required_count: int, delay_seconds: float = 0.5):\n",
    "    thread_ids = []\n",
    "    attempt = 0\n",
    "\n",
    "    while len(thread_ids) < required_count:\n",
    "        attempt += 1\n",
    "        try:\n",
    "            response = requests.post(BASE_URL, headers=HEADERS, json=thread_init_payload)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            thread_id = response.json().get(\"chatId\")\n",
    "            if thread_id:\n",
    "                thread_ids.append(thread_id)\n",
    "            else:\n",
    "                print(f\"[Attempt {attempt}] No chatId in response.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Attempt {attempt}] Failed to create thread: {e}\")\n",
    "            try:\n",
    "                print(\"Raw response:\", response.text)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        time.sleep(delay_seconds)\n",
    "\n",
    "    print(\"‚úÖ All threads created.\\n\")\n",
    "    return thread_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e7f47c8-f2ea-42bf-8442-121ffef08a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    questions = [pair[\"question\"] for pair in qa_pairs]\n",
    "    expected_outcomes = [pair[\"expected_outcomes\"] for pair in qa_pairs]\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create chat threads\n",
    "    thread_ids = create_chat_threads(required_count=len(qa_pairs))\n",
    "\n",
    "    # Send prompts and evaluate responses\n",
    "    await orchestrator.send_prompts_async(\n",
    "        prompt_list=questions,\n",
    "        expected_output_list=expected_outcomes,\n",
    "        thread_ids=thread_ids\n",
    "    )\n",
    "\n",
    "    # Collect results and execution time\n",
    "    results = orchestrator.get_chat_results()\n",
    "    execution_time = time.time() - start_time\n",
    "\n",
    "    # Save HTML report\n",
    "    report_dir = Path(\"tests/E2E/reports/DataSet\").resolve()\n",
    "    report_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    save_html_report(\n",
    "        results=results,\n",
    "        directory=str(report_dir),\n",
    "        report_generator=generate_single_turn_html_report,\n",
    "        is_chat_evaluation=False,\n",
    "        threshold=0.7,\n",
    "        file_name=\"ah_gpt_dataset\",\n",
    "        description=\"Evaluation of inputs vs. expected/actual outputs with scoring.\",\n",
    "        execution_time=execution_time\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a6fab32-4dca-47b1-9ad5-ade3bd9f9786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All threads created.\n",
      "\n",
      "‚úÖ Report saved at: /Users/denizdalkilic/Documents/Forks/PyRIT/tests/E2E/reports/DataSet/ah_gpt_dataset_20250328_151011.html\n"
     ]
    }
   ],
   "source": [
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
