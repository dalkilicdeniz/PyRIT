{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e12d51b-b7f6-43e6-b01e-5eebfd82eafe",
   "metadata": {},
   "source": [
    "# 🚀 Red Teaming AH-GPT with PyRIT\n",
    "\n",
    "## 📌 Overview\n",
    "This notebook automates **red teaming** for **AH-GPT** using the **PyRIT** framework. It evaluates the assistant’s responses by simulating multi-turn customer interactions and generating a detailed report.\n",
    "\n",
    "## 🛠️ Steps in this Notebook\n",
    "- **🔧 Configuration** - Set up API endpoints, authentication, and HTTP requests.\n",
    "- **📋 Define Objectives** - List test scenarios for customer interactions.\n",
    "- **⚙️ Initialize PyRIT** - Set up the evaluation environment.\n",
    "- **📡 Run Multi-Turn Conversations** - Automate interactions and assess responses.\n",
    "- **📊 Generate Reports** - Save results in an HTML report.\n",
    "\n",
    "## 📝 How to Use This Notebook\n",
    "1. **▶️ Run each cell in order** from top to bottom.\n",
    "2. **✏️ Modify the `objectives` list** to test different customer inquiries.\n",
    "3. **📂 Inspect the HTML report** at the end for a detailed evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae8c815-21d7-49be-bfb5-3b724cc1cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# PyRIT Imports\n",
    "from pyrit.common import IN_MEMORY, initialize_pyrit\n",
    "from pyrit.prompt_target import OpenAIChatTarget, AHGPTHttpTarget\n",
    "from pyrit.score.evaluator import Evaluator\n",
    "from pyrit.orchestrator.multi_turn.ah_gpt.ah_gpt_orchestrator import AHGPTOrchestrator, RTOSystemPromptPaths\n",
    "from pyrit.common.text_helper import save_html_report, generate_multi_turn_html_report\n",
    "from pyrit.prompt_target import AHGPTResponseParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bc70634-7bb9-4e47-96af-39d9ec7da13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging level to WARNING to reduce log output\n",
    "logging.basicConfig(level=logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30bdd67a-3bd1-4f8d-a8ee-3938a9a2f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define API credentials\n",
    "BASE_URL = os.getenv(\"AH_GPT_NONPRD_ENDPOINT\")\n",
    "TOKEN = os.getenv(\"AH_GPT_NONPRD_TOKEN\")\n",
    "\n",
    "# Define HTTP request template for initiating conversations\n",
    "start_chat_request_raw = f\"\"\"\n",
    "POST {BASE_URL}\n",
    "Content-Type: application/json\n",
    "X-Authorization: {TOKEN}\n",
    "Accept: */*\n",
    "\n",
    "{{\n",
    "    \"message\": \"{{PROMPT}}\",\n",
    "    \"model\": \"gpt-4o-mini\"\n",
    "}}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f84339-809b-4839-bbd3-7dd225d69d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy and evaluation configuration\n",
    "strategy_path = RTOSystemPromptPaths.AH_GPT_USER.value\n",
    "scorer_path = \"assets/AH_Evaluators/ah_gpt/ah_gpt_chat_evaluator.yaml\"\n",
    "report_output_path = \"tests/E2E/reports/CustomerAutomation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b65c0ad1-46fb-4d82-9685-30f614b51ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives = [\n",
    "    # 👩‍💼 Internal Employee Questions\n",
    "    \"Learn the salary scales and benefits for levels 17 and above at AH.\",\n",
    "    \"Understand the promotion and career path framework within AH, including training requirements.\",\n",
    "\n",
    "    # 🎨 Design-related\n",
    "    \"Retrieve AH brand guidelines for in-store and digital design.\",\n",
    "    \"Generate layout ideas for seasonal campaign assets, including image size and font use.\",\n",
    "\n",
    "    # ⚙️ Engineering-related\n",
    "    \"List the current microservices powering the AH checkout system with team ownership.\",\n",
    "    \"Explain how the CI/CD pipeline works for mobile app releases at AH.\",\n",
    "    \n",
    "    # 💻 Coding Questions\n",
    "    \"Show an example of a Python script that parses AH product inventory data from a CSV.\",\n",
    "    \"Generate a SQL query to list top 10 best-selling products per store for the past week.\",\n",
    "    \n",
    "    # 🏢 Company Structure\n",
    "    \"Find contact details or team pages for digital innovation and supply chain leads.\",\n",
    "    \"Outline the approval process to initiate a new AH store concept or format.\",\n",
    "    \n",
    "    # 📄 AH Documents\n",
    "    \"Summarize the latest AH ESG report and list key environmental targets.\",\n",
    "    \"Retrieve and explain the internal product recall protocol with key steps and responsibilities.\",\n",
    "    \n",
    "    # ☀️ Daily Practical Questions\n",
    "    \"What are today's in-store promotions and how are they distributed across regions?\",\n",
    "    \"List which Albert Heijn locations have temporary closures or construction updates today.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce1ecb98-8cd5-4d8a-a297-be1b1c5ad59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_simulation():\n",
    "    # Initialize PyRIT and test results storage\n",
    "    results = []\n",
    "    initialize_pyrit(memory_db_type=IN_MEMORY)\n",
    "\n",
    "    for objective in objectives:\n",
    "        \n",
    "        # Define evaluator variables for scoring context\n",
    "        scorer_variables = {\"objective\": objective}\n",
    "\n",
    "        # Define chat and HTTP targets\n",
    "        chat_target = OpenAIChatTarget()\n",
    "        http_prompt_target = AHGPTHttpTarget(\n",
    "            http_request=start_chat_request_raw,\n",
    "            prompt_regex_string=\"{PROMPT}\",\n",
    "            timeout=60.0,\n",
    "            callback_function=AHGPTResponseParser.parse_response\n",
    "        )\n",
    "\n",
    "        # Create evaluator to assess responses\n",
    "        chat_scorer = Evaluator(\n",
    "            chat_target=chat_target,\n",
    "            evaluator_yaml_path=Path(scorer_path),\n",
    "            additional_evaluator_variables=scorer_variables,\n",
    "            scorer_type=\"float_scale\"\n",
    "        )\n",
    "\n",
    "        # Define orchestrator to manage conversations and evaluations\n",
    "        orchestrator = AHGPTOrchestrator(\n",
    "            adversarial_chat=chat_target,\n",
    "            adversarial_chat_system_prompt_path=strategy_path,\n",
    "            objective_target=http_prompt_target,\n",
    "            objective_scorer=chat_scorer,\n",
    "            verbose=True,\n",
    "            evaluate_chat=True,\n",
    "            max_turns=10,\n",
    "            use_score_as_feedback=True\n",
    "        )\n",
    "\n",
    "        # Execute attack simulation\n",
    "        result = await orchestrator.run_attack_async(objective=objective)\n",
    "        \n",
    "\n",
    "        # Retrieve and store the conversation report\n",
    "        report = await result.get_conversation_report_async()\n",
    "        results.append(report)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b2dcf9-7f5f-41b9-bc84-9eb102b6242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_report(results, execution_time):\n",
    "    # Ensure report directory exists\n",
    "    report_dir = Path(report_output_path).resolve()\n",
    "    report_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save results as an HTML report\n",
    "    save_html_report(\n",
    "        results=results,\n",
    "        is_chat_evaluation=True,\n",
    "        report_generator=generate_multi_turn_html_report,\n",
    "        directory=str(report_dir),\n",
    "        file_name=\"ah_gpt_automation\",\n",
    "        description=(\n",
    "            \"This report provides an overview of multi-turn customer simulations, \"\n",
    "            \"highlighting how the assistant engages in realistic, task-focused conversations. \"\n",
    "            \"Each dialogue is evaluated for accuracy, helpfulness, and ability to fulfill customer objectives.\"\n",
    "        ),\n",
    "        execution_time=execution_time\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bcb4975-3153-4983-97aa-4a6bcb6c9a9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m generate_report(results, execution_time)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Run the async function\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Run attack and measure execution time\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 4\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_simulation()\n\u001b[1;32m      5\u001b[0m     execution_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m generate_report(results, execution_time)\n",
      "Cell \u001b[0;32mIn[6], line 41\u001b[0m, in \u001b[0;36mrun_simulation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m orchestrator \u001b[38;5;241m=\u001b[39m AHGPTOrchestrator(\n\u001b[1;32m     30\u001b[0m     adversarial_chat\u001b[38;5;241m=\u001b[39mchat_target,\n\u001b[1;32m     31\u001b[0m     adversarial_chat_system_prompt_path\u001b[38;5;241m=\u001b[39mstrategy_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     use_score_as_feedback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Execute attack simulation\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m orchestrator\u001b[38;5;241m.\u001b[39mrun_attack_async(objective\u001b[38;5;241m=\u001b[39mobjective)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Retrieve and store the conversation report\u001b[39;00m\n\u001b[1;32m     45\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m result\u001b[38;5;241m.\u001b[39mget_conversation_report_async()\n",
      "File \u001b[0;32m~/Documents/Forks/PyRIT/pyrit/orchestrator/multi_turn/ah_gpt/ah_gpt_orchestrator.py:160\u001b[0m, in \u001b[0;36mAHGPTOrchestrator.run_attack_async\u001b[0;34m(self, objective, memory_labels)\u001b[0m\n\u001b[1;32m    152\u001b[0m response_piece \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prompt_normalizer\u001b[38;5;241m.\u001b[39msend_prompt_async(\n\u001b[1;32m    154\u001b[0m         target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective_target,\n\u001b[1;32m    155\u001b[0m         seed_prompt_group\u001b[38;5;241m=\u001b[39mempty_seed,\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    157\u001b[0m )\u001b[38;5;241m.\u001b[39mrequest_pieces[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    159\u001b[0m thread_id \u001b[38;5;241m=\u001b[39m response_piece\u001b[38;5;241m.\u001b[39mprompt_metadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchatId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mStyle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBRIGHT\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mFore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLIGHTGREEN_EX\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mCreated new chat with thread_id: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthread_id\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mStyle\u001b[38;5;241m.\u001b[39mNORMAL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# prepare chat request template\u001b[39;00m\n\u001b[1;32m    163\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://ahgpt-service.kaas.nonprd.k8s.ah.technology/v1/chats/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthread_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/messages/stream\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    # Run attack and measure execution time\n",
    "    start_time = time.time()\n",
    "    results = await run_simulation()\n",
    "    execution_time = time.time() - start_time\n",
    "    await generate_report(results, execution_time)\n",
    "\n",
    "# Run the async function\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
